{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting game-level data from the Lithuanian Basketball League website\n",
    "\n",
    "In this notebook, I collect all information about all games that have ever taken in the Lithuanian Basketball League since season 1993-1994, including the games played in the King Mindaugas Cup. All the information is saved into a SQLite database for further processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lxml    : 4.8.0\n",
      "pandas  : 1.4.2\n",
      "requests: 2.27.1\n",
      "sqlite3 : 2.6.0\n",
      "sys     : 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:22:55) \n",
      "[GCC 10.3.0]\n",
      "re      : 2.2.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import re\n",
    "import itertools as itt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import sqlite3 as sq\n",
    "\n",
    "DB_PATH = '../data/data.sqlite.db'\n",
    "\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I get a list of teams participating in the Lithuanian Basketball League in the season 2021-2022, with their IDs and seasons the teams participated in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://lkl.lt/turnyrine-lentele\")\n",
    "teams = {tag.text.strip(): {'homepage':  tag[\"href\"], 'name': tag.text.strip()} for tag in BeautifulSoup(r.text, 'lxml').find_all('a', class_='team-title')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_info(html, team):\n",
    "    \n",
    "    #get ID\n",
    "    pattern = re.compile(\"window.teamId = (\\d+);\")\n",
    "    match = pattern.search(html)\n",
    "    if match:\n",
    "        team['id'] = match.group(1)\n",
    "    else:\n",
    "        print(\"Warning - no team ID found for %s\" % team['name'])\n",
    "    \n",
    "    #get seasons\n",
    "    team['seasons'] = {}\n",
    "    seasons = [s.find_all(\"option\") for s in BeautifulSoup(html, 'lxml').find_all(class_=\"season-id\")]\n",
    "    if not seasons:\n",
    "        print(\"Warning - no seasons found for %s\" % team['name'])\n",
    "    for season in itt.chain(*seasons):\n",
    "        team['seasons'][season.text.strip()] = season['value']\n",
    "    \n",
    "\n",
    "for name, team in tqdm(teams.items()):\n",
    "    homepage = requests.get(team['homepage'])\n",
    "    update_info(homepage.text, team)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I collect all seasons observed with their associated IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for season, id in itt.chain(*[team['seasons'].items() for team in teams.values()]):\n",
    "    seasons[season]['participants'] += 1\n",
    "    if seasons[season]['id'] == 0:\n",
    "        seasons[season]['id'] = id\n",
    "    elif seasons[season]['id'] != id:\n",
    "        print(\"Season %s has multiple IDs in data! %s and %s\" % season, id, seasons[season]['id'])\n",
    "    seasons[season]['name'] = season\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I go through all the seasons and collect all individual game data, recording the location, score, home and away teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:04<00:00,  5.11s/it]\n"
     ]
    }
   ],
   "source": [
    "def parse_result_page(html, url, season_id):\n",
    "    gameid_pattern = re.compile(\"https\\:\\/\\/lkl\\.lt\\/rungtynes\\/(\\d+)\")\n",
    "    gamescore_pattern = re.compile(\"(\\d+) - (\\d+)\")\n",
    "\n",
    "    games = []\n",
    "    for game in html.find_all(\"div\", class_=\"result-item\"):\n",
    "        gameinfo = {\"season_id\" : season_id}\n",
    "        \n",
    "        #get location\n",
    "        gameinfo['location'] = game.find(\"div\", class_=\"location\").text.strip()\n",
    "        \n",
    "        #get game id \n",
    "        result = game.find(\"span\", class_=\"result\").find(\"a\")\n",
    "        idmatch = gameid_pattern.search(result['href'])\n",
    "        if idmatch:\n",
    "            gameinfo['game-id'] = idmatch.group(1)\n",
    "        else: \n",
    "            print(\"No game ID found for game %s (page %s)\" % result['href'], url)\n",
    "        \n",
    "        #get game score         \n",
    "        score_match = gamescore_pattern.search(result.text)\n",
    "        if score_match:\n",
    "            gameinfo['home-points'] = int(score_match.group(1))\n",
    "            gameinfo['away-points'] = int(score_match.group(2))\n",
    "        else:\n",
    "            print(\"No game score found for game %s (page %s)\" % result.text, url)\n",
    "\n",
    "        #get teams\n",
    "        links = game.find(\"div\", class_=\"battle-row\").find_all(\"a\")\n",
    "        gameinfo['home-team-url'] = links[0]['href']\n",
    "        gameinfo['home-team-name'] = links[0].text.strip()\n",
    "\n",
    "        gameinfo['away-team-url'] = links[4]['href']\n",
    "        gameinfo['away-team-name'] = links[4].text.strip()\n",
    "        games.append(gameinfo)\n",
    "    \n",
    "    return games\n",
    "\n",
    "def failsafe_int(text):\n",
    "    try: \n",
    "        return int(text)\n",
    "    except ValueError: \n",
    "        return -1\n",
    "\n",
    "\n",
    "all_games = []\n",
    "for season in tqdm(seasons.values()):\n",
    "    #get the first page of the results \n",
    "    params = {\n",
    "        \"team\": \"-\",\n",
    "        \"month\": \"-\",\n",
    "        \"season\" : season['id'],\n",
    "        \"page\" : 1\n",
    "    }\n",
    "    firstpage = requests.get(\"https://lkl.lt/loadResults\", params=params)\n",
    "    html = BeautifulSoup(firstpage.text, 'lxml')\n",
    "    \n",
    "    #parse the games in the first page\n",
    "    games = parse_result_page(html=html, url = firstpage.url, season_id=season['id'])\n",
    "    all_games += games\n",
    "    \n",
    "    #get number of pages\n",
    "    page_numbers = [failsafe_int(p.text) for p in html.find_all(class_= \"page-link\")]\n",
    "    if page_numbers:\n",
    "        max_page = max(page_numbers)\n",
    "\n",
    "        #parse all subsequent pages \n",
    "        for pageNo in range(2, max_page + 1):\n",
    "            params['page'] = pageNo\n",
    "            page = requests.get(\"https://lkl.lt/loadResults\", params=params)\n",
    "            html = BeautifulSoup(page.text, 'lxml')\n",
    "            games = parse_result_page(html=html, url = page.url, season_id=season['id'])\n",
    "            all_games += games    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing collected information\n",
    "\n",
    "In this section I:\n",
    " - Add team abbreviations to the known team list\n",
    " - Add teams that are observed in the historical data but no longer play in the championship to the team list\n",
    " - Reorganize data into a better structure and save to a SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding team abbreviations to current teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_teams = set([(g['home-team-url'], g['home-team-name']) for g in all_games])\n",
    "away_teams = set([(g['away-team-url'], g['away-team-name']) for g in all_games])\n",
    "all_teams = home_teams.union(away_teams)\n",
    "\n",
    "team_dict = dict(all_teams)\n",
    "for team in teams.values():\n",
    "    team['abbreviation'] = team_dict[team['homepage']]\n",
    "    team['current_team'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding missing teams to the list (and giving them \"fake\" IDs for consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_current_teams = set([(t['homepage'], t['abbreviation']) for t in teams.values()])\n",
    "no_longer_playing_teams = all_teams.difference(all_current_teams)\n",
    "\n",
    "i = 999\n",
    "for team_url, team_abbr in no_longer_playing_teams:\n",
    "    name = team_abbr + \"_\" + str(i)\n",
    "    teams[name] = {\n",
    "        'current_team': False,\n",
    "        'homepage': team_url,\n",
    "        'abbreviation': team_abbr,\n",
    "        'id' : i,\n",
    "        'name': name,\n",
    "    }\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing all the data and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df = pd.DataFrame(teams.values())\n",
    "games_df = pd.DataFrame(all_games)\n",
    "seasons_df = pd.DataFrame(seasons.values())\n",
    "\n",
    "teams_df.drop(['seasons'], axis=1, inplace=True)\n",
    "seasons_df.drop(['participants'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organizing games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_home = pd.merge(games_df, teams_df, left_on=['home-team-url', 'home-team-name'], right_on=['homepage', 'abbreviation']).rename({\"id\": \"home-team-id\"}, axis=1)\n",
    "with_away = pd.merge(with_home, teams_df, left_on=['away-team-url', 'away-team-name'], right_on=['homepage', 'abbreviation']).rename({\"id\": \"away-team-id\"}, axis=1)\n",
    "\n",
    "cols_of_interest = ['season_id', 'location', 'game-id', 'home-points', 'away-points', 'home-team-id', 'away-team-id']\n",
    "clean_game_df = with_away[cols_of_interest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing season information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs = seasons_df['name'].str.extract(\"(\\d+)-?(\\d+)?\")\n",
    "seasons_df['start-year'] = yrs[0]\n",
    "seasons_df['end-year'] = yrs[1]\n",
    "\n",
    "seasons_df['Regular'] = ~seasons_df['name'].str.contains(\"KMT\")\n",
    "seasons_df.replace(pd.NA, None, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to SQlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sq.connect(DB_PATH) as conn:\n",
    "    teams_df.to_sql(\"teams\", conn, if_exists='replace', index=False) \n",
    "    clean_game_df.to_sql(\"games\", conn, if_exists='replace', index=False) \n",
    "    seasons_df.to_sql(\"seasons\", conn, if_exists='replace', index=False) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a0eed5a239e5616891a884969c665ca0b86fc2fde1f66977325082d5a2189cd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('homecourt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
